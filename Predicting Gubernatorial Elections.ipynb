{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Gubernatorial Elections <br/> PPHA 31720 – The Science of Elections and Politics (Fall, 2019)\n",
    "\n",
    "### Overview \n",
    "The goal of this analysis is to predict the outcome of the 2019 gubernatorial elections in Kentucky, Louisiana, and Mississippi. To make these predictions, I use information on the incumbency status of the candidates, polling data, and historical presidential and gubernatorial election results. I then train a simple machine learning model on the data from the 2018 gubernatorial elections, and then use this model to predict the election results for the 2019 gubernatorial elections. My model predicts the following – \n",
    "- Kentucky: Democratic nominee Andy Beshear will receive 48.81% of the two-party vote share  \n",
    "- Louisiana: Democratic nominee John Bel Edwards will receive 50.00% of the two-party vote share \n",
    "- Mississippi: Democratic nominee Jim Hood will receive 46.95% of the two-party vote share\n",
    "\n",
    "### Methodology \n",
    "\n",
    "#### Model Specification\n",
    "My target – or the variable I am trying to predict – is the Democratic candidate's share of the two-party vote (`dem_vtsh_actual`). To do so, I include five features – \n",
    " \n",
    "- `dem_incumbent`: Whether the Democratic candidate is the incumbent\n",
    "- `rep_incumbent`: Whether the Republican candidate is the incumbent \n",
    "- `dem_vtsh_poll`: The Democratic candidate's share of the two-party vote in the most recent poll \n",
    "- `dem_vtsh_last_gov`: The Democratic candidate's share of the two-party vote in the last gubernatorial election \n",
    "- `dem_vtsh_2016_pres`: Hillary Clinton's share of the two-party vote in the 2016 presidential election\n",
    "\n",
    "Using data on the 36 gubernatorial elections in 2018, I build a random forest regression model, one of the most common – and often best-performing –  machine learning models in predictive analytics. I chose this model over, for example, a linear regression because random forests are able to capture non-linear interactions between the features and the target, which are likely relevant in this context. Additionally, given the small size of the training set here, a bagging ensemble method like a random forest can prevent over-fitting.  \n",
    "\n",
    "#### Data Sources & Feature Generation\n",
    "Using election results data from [Dave Leip's Atlas of U.S. Elections](https://uselectionatlas.org/RESULTS/), I compute the Democratic candidate's share of the two-party vote in gubernatorial elections in 2018 for the 36 training elections (`dem_vtsh_actual`) and in each state's most recent gubernatorial election – 2014 for the 36 training elections and 2015 for the three predicted states (`dem_vtsh_last_gov`). In both cases, this was simply the number of votes received by the Democratic candidate over the number of votes received by the Democratic and Republican candidates combined. I also compute Hillary Clinton's share of the two-party vote in the 2016 presidential election as the number of votes that she received over the total number of votes that she and Donald Trump received in each state (`dem_vtsh_2016_pres`). \n",
    "\n",
    "I use [FiveThirtyEight's gubernatorial forecast data](https://github.com/fivethirtyeight/data/tree/master/governors-forecast-2018) to pull information on whether the Democratic or Republican candidate running in the election is the incumbent. Note that I do NOT use the numerical precictions from the forecast – I simply use the party and incumbency status fields included in this dataset to create indicator variables for whether each election has an incumbent Democrat running (`dem_incumbent`) or incumbent Republican running (`rep_incumbent`). \n",
    "\n",
    "Finally, I use [FiveThirtyEight's gubernatorial polls](https://projects.fivethirtyeight.com/polls/governor/) to compute the Democratic candidate's predicted share of the two-party vote in the single most recent poll available for each election (`dem_vtsh_poll`). For Mississippi's election, this was the Mason-Dixon poll released on October 23. Louisiana's most recent poll was the We Ask America poll released on October 17, and Kentucky's most recent poll was the Mason-Dixon poll released on October 16. For the 2018 races, the poll released closest to the actual elections were used. \n",
    "\n",
    "The fully reproducible code used to generate these predictions is shown below. This also includes the full modelling dataset, with the full set of features and target for the 2018 and 2019 gubernatorial elections. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules \n",
    "First, I import the Python libraries and packages used in this analysis. This includes `predicting_elections`, which contains the helper functions used below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import predicting_elections as pred "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Features\n",
    "Next, I generate the target and five features discussed above (`dem_incumbent`, `rep_incumbent`, `dem_vtsh_poll`, `dem_vtsh_last_gov`, and `dem_vtsh_2016_pres`). This process relies upon the helper functions called from `predicting_elections` to wrangle the raw data. This creates five separate datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# wrangle dem_vtsh_actual \n",
    "gov_results_18 = pred.wrangle_dem_vtshr('raw/2018_gov_election_results.csv', \n",
    "                                        'dem_vtsh_actual', \n",
    "                                        'Democr..1', \n",
    "                                        'Republ..1', \n",
    "                                        'State')\n",
    "new_rows = [{'State': 'Kentucky', 'dem_vtsh_actual': np.NaN}, \n",
    "            {'State': 'Louisiana', 'dem_vtsh_actual': np.NaN}, \n",
    "            {'State': 'Mississippi', 'dem_vtsh_actual': np.NaN}]\n",
    "gov_results_18 = pred.append_rows(gov_results_18, new_rows)\n",
    "\n",
    "# wrangle dem_incumbent / rep_incumbent\n",
    "incumbents = pred.wrangle_incumbents('raw/governor_state_forecast.csv')\n",
    "new_rows = [{'state': 'KY', 'dem_incumbent': 0, 'rep_incumbent': 1}, \n",
    "            {'state': 'LA', 'dem_incumbent': 1, 'rep_incumbent': 0}, \n",
    "            {'state': 'MS', 'dem_incumbent': 0, 'rep_incumbent': 0}]\n",
    "incumbents = pred.append_rows(incumbents, new_rows)\n",
    "\n",
    "# wrangle dem_vtsh_poll\n",
    "polls = pred.wrangle_dem_poll('raw/governor_polls.csv')\n",
    "\n",
    "# wrangle dem_vtsh_2016_pres\n",
    "pres_results = pred.wrangle_dem_vtshr('raw/2016_pres_election_results.csv', \n",
    "                                      'dem_vtsh_2016_pres', \n",
    "                                      'Clinton.1', \n",
    "                                      'Trump.1',\n",
    "                                      'State')\n",
    "\n",
    "# wrangle dem_vtsh_last_gov\n",
    "gov_results_last = pred.wrangle_dem_vtshr('raw/last_gov_election_results.csv', \n",
    "                                          'dem_vtsh_last_gov', \n",
    "                                          'Democr..1', \n",
    "                                          'Republ..1',\n",
    "                                          'State')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Datasets\n",
    "\n",
    "I next combine the five datasets created above to get a single dataset (`merged`) with the full set of five features and the target. I also print out this final modelling dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>dem_vtsh_actual</th>\n",
       "      <th>dem_incumbent</th>\n",
       "      <th>rep_incumbent</th>\n",
       "      <th>dem_vtsh_poll</th>\n",
       "      <th>dem_vtsh_2016_pres</th>\n",
       "      <th>dem_vtsh_last_gov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>0.404493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.356259</td>\n",
       "      <td>0.636859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.463349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.498821</td>\n",
       "      <td>0.416143</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.427636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.421687</td>\n",
       "      <td>0.481100</td>\n",
       "      <td>0.562201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>0.327184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.357149</td>\n",
       "      <td>0.571920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>0.619485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563830</td>\n",
       "      <td>0.661282</td>\n",
       "      <td>0.400298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>0.555169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.526833</td>\n",
       "      <td>0.482455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>0.516499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.554217</td>\n",
       "      <td>0.571415</td>\n",
       "      <td>0.487036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Florida</td>\n",
       "      <td>0.498001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.482402</td>\n",
       "      <td>0.493812</td>\n",
       "      <td>0.505660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>0.492988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.473388</td>\n",
       "      <td>0.540249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>0.650291</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.626506</td>\n",
       "      <td>0.674413</td>\n",
       "      <td>0.428473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>0.389851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.414894</td>\n",
       "      <td>0.316898</td>\n",
       "      <td>0.581303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>0.584089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.597561</td>\n",
       "      <td>0.590201</td>\n",
       "      <td>0.520297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>0.486024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.515789</td>\n",
       "      <td>0.449365</td>\n",
       "      <td>0.612815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>0.527867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492554</td>\n",
       "      <td>0.388885</td>\n",
       "      <td>0.519235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Maine</td>\n",
       "      <td>0.541002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.591398</td>\n",
       "      <td>0.515968</td>\n",
       "      <td>0.526273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>0.440085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.640162</td>\n",
       "      <td>0.519230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>0.332108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.268817</td>\n",
       "      <td>0.646513</td>\n",
       "      <td>0.509801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>0.549283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.543820</td>\n",
       "      <td>0.498823</td>\n",
       "      <td>0.520791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>0.559296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563830</td>\n",
       "      <td>0.508285</td>\n",
       "      <td>0.470601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>0.409995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.364523</td>\n",
       "      <td>0.593004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>0.521561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501126</td>\n",
       "      <td>0.512937</td>\n",
       "      <td>0.747183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>0.464251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.501970</td>\n",
       "      <td>0.475214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>New Mexico</td>\n",
       "      <td>0.571991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563830</td>\n",
       "      <td>0.546508</td>\n",
       "      <td>0.572231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>New York</td>\n",
       "      <td>0.622176</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.593407</td>\n",
       "      <td>0.617723</td>\n",
       "      <td>0.426158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>0.480921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>0.457324</td>\n",
       "      <td>0.658332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>0.437320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484083</td>\n",
       "      <td>0.306953</td>\n",
       "      <td>0.576427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>0.534156</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.561558</td>\n",
       "      <td>0.469355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.557895</td>\n",
       "      <td>0.496245</td>\n",
       "      <td>0.450678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>0.586066</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.569054</td>\n",
       "      <td>0.583107</td>\n",
       "      <td>0.470980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>0.459789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.412338</td>\n",
       "      <td>0.425397</td>\n",
       "      <td>0.574405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>0.482866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.340281</td>\n",
       "      <td>0.734804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>0.392946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.453608</td>\n",
       "      <td>0.363757</td>\n",
       "      <td>0.754775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Texas</td>\n",
       "      <td>0.432366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.455804</td>\n",
       "      <td>0.452868</td>\n",
       "      <td>0.603726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>0.421776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.443182</td>\n",
       "      <td>0.651864</td>\n",
       "      <td>0.493108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>0.505579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.495920</td>\n",
       "      <td>0.528706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>0.290913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306818</td>\n",
       "      <td>0.242947</td>\n",
       "      <td>0.685449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.343294</td>\n",
       "      <td>0.545178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.398283</td>\n",
       "      <td>0.438855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483146</td>\n",
       "      <td>0.409102</td>\n",
       "      <td>0.672978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             State  dem_vtsh_actual  dem_incumbent  rep_incumbent  \\\n",
       "0          Alabama         0.404493            0.0            1.0   \n",
       "1           Alaska         0.463349            0.0            0.0   \n",
       "2          Arizona         0.427636            0.0            1.0   \n",
       "3         Arkansas         0.327184            0.0            1.0   \n",
       "4       California         0.619485            0.0            0.0   \n",
       "5         Colorado         0.555169            0.0            0.0   \n",
       "6      Connecticut         0.516499            0.0            0.0   \n",
       "7          Florida         0.498001            0.0            0.0   \n",
       "8          Georgia         0.492988            0.0            0.0   \n",
       "9           Hawaii         0.650291            1.0            0.0   \n",
       "10           Idaho         0.389851            0.0            0.0   \n",
       "11        Illinois         0.584089            0.0            1.0   \n",
       "12            Iowa         0.486024            0.0            1.0   \n",
       "13          Kansas         0.527867            0.0            0.0   \n",
       "14           Maine         0.541002            0.0            0.0   \n",
       "15        Maryland         0.440085            0.0            1.0   \n",
       "16   Massachusetts         0.332108            0.0            1.0   \n",
       "17        Michigan         0.549283            0.0            0.0   \n",
       "18       Minnesota         0.559296            0.0            0.0   \n",
       "19        Nebraska         0.409995            0.0            1.0   \n",
       "20          Nevada         0.521561            0.0            0.0   \n",
       "21   New Hampshire         0.464251            0.0            1.0   \n",
       "22      New Mexico         0.571991            0.0            0.0   \n",
       "23        New York         0.622176            1.0            0.0   \n",
       "24            Ohio         0.480921            0.0            0.0   \n",
       "25        Oklahoma         0.437320            0.0            0.0   \n",
       "26          Oregon         0.534156            1.0            0.0   \n",
       "27    Pennsylvania         0.586695            1.0            0.0   \n",
       "28    Rhode Island         0.586066            1.0            0.0   \n",
       "29  South Carolina         0.459789            0.0            1.0   \n",
       "30    South Dakota         0.482866            0.0            0.0   \n",
       "31       Tennessee         0.392946            0.0            0.0   \n",
       "32           Texas         0.432366            0.0            1.0   \n",
       "33         Vermont         0.421776            0.0            1.0   \n",
       "34       Wisconsin         0.505579            0.0            1.0   \n",
       "35         Wyoming         0.290913            0.0            0.0   \n",
       "36        Kentucky              NaN            0.0            1.0   \n",
       "37       Louisiana              NaN            1.0            0.0   \n",
       "38     Mississippi              NaN            0.0            0.0   \n",
       "\n",
       "    dem_vtsh_poll  dem_vtsh_2016_pres  dem_vtsh_last_gov  \n",
       "0        0.391304            0.356259           0.636859  \n",
       "1        0.498821            0.416143           1.000000  \n",
       "2        0.421687            0.481100           0.562201  \n",
       "3        0.285714            0.357149           0.571920  \n",
       "4        0.563830            0.661282           0.400298  \n",
       "5        0.529412            0.526833           0.482455  \n",
       "6        0.554217            0.571415           0.487036  \n",
       "7        0.482402            0.493812           0.505660  \n",
       "8        0.520833            0.473388           0.540249  \n",
       "9        0.626506            0.674413           0.428473  \n",
       "10       0.414894            0.316898           0.581303  \n",
       "11       0.597561            0.590201           0.520297  \n",
       "12       0.515789            0.449365           0.612815  \n",
       "13       0.492554            0.388885           0.519235  \n",
       "14       0.591398            0.515968           0.526273  \n",
       "15       0.391304            0.640162           0.519230  \n",
       "16       0.268817            0.646513           0.509801  \n",
       "17       0.543820            0.498823           0.520791  \n",
       "18       0.563830            0.508285           0.470601  \n",
       "19            NaN            0.364523           0.593004  \n",
       "20       0.501126            0.512937           0.747183  \n",
       "21       0.500000            0.501970           0.475214  \n",
       "22       0.563830            0.546508           0.572231  \n",
       "23       0.593407            0.617723           0.426158  \n",
       "24       0.527473            0.457324           0.658332  \n",
       "25       0.484083            0.306953           0.576427  \n",
       "26       0.517241            0.561558           0.469355  \n",
       "27       0.557895            0.496245           0.450678  \n",
       "28       0.569054            0.583107           0.470980  \n",
       "29       0.412338            0.425397           0.574405  \n",
       "30       0.531250            0.340281           0.734804  \n",
       "31       0.453608            0.363757           0.754775  \n",
       "32       0.455804            0.452868           0.603726  \n",
       "33       0.443182            0.651864           0.493108  \n",
       "34       0.505618            0.495920           0.528706  \n",
       "35       0.306818            0.242947           0.685449  \n",
       "36       0.500000            0.343294           0.545178  \n",
       "37       0.500000            0.398283           0.438855  \n",
       "38       0.483146            0.409102           0.672978  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine dfs  \n",
    "gov_results_18['state'] = gov_results_18['State'].apply(lambda x: pred.get_abbr(x))\n",
    "merged = gov_results_18.merge(\n",
    "    incumbents, on = 'state', how = 'left').merge(\n",
    "    polls, left_on = 'State', right_on = 'state', how = 'left').merge(\n",
    "    pres_results, on = 'State', how = 'left').merge(\n",
    "    gov_results_last, on = 'State').drop(['state_x', 'state_y'], axis=1)\n",
    "\n",
    "# replace if neither candidate is an incumbent \n",
    "merged['dem_incumbent'].fillna(0, inplace=True)\n",
    "merged['rep_incumbent'].fillna(0, inplace=True)\n",
    "\n",
    "# print full modeling dataset \n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Model \n",
    "Next I actually build the machine learning model by fitting to the training data – or on the 2018 elections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify model parameters \n",
    "features = ['dem_incumbent', \n",
    "            'rep_incumbent', \n",
    "            'dem_vtsh_poll', \n",
    "            'dem_vtsh_2016_pres', \n",
    "            'dem_vtsh_last_gov', \n",
    "            'dem_vtsh_last_gov']\n",
    "target = 'dem_vtsh_actual'\n",
    "\n",
    "# split training and testing data \n",
    "X_train, y_train, X_test, test = pred.split(merged, target, features)\n",
    "\n",
    "# fit model \n",
    "rfr = RandomForestRegressor(n_estimators = 10)\n",
    "rfr.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Predictions\n",
    "\n",
    "Finally, I use the model built above to predict elections results for the 2019 elections, and print out these predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>dem_vtsh_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>0.488137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>0.500352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>0.469504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          State  dem_vtsh_predicted\n",
       "36     Kentucky            0.488137\n",
       "37    Louisiana            0.500352\n",
       "38  Mississippi            0.469504"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions \n",
    "test['dem_vtsh_predicted'] = rfr.predict(X_test)\n",
    "test[['State', 'dem_vtsh_predicted']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
